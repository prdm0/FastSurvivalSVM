---
title: "Bagging with FastSurvivalSVM"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Bagging with FastSurvivalSVM}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Introduction

The **FastSurvivalSVM** package provides a flexible and robust implementation of Bagging (Bootstrap Aggregating) for survival analysis. This implementation allows for the creation of *Random Survival Machines* by combining three sources of diversity:

- **Row Subsampling**: Standard bootstrap aggregation (sampling with replacement).  
- **Kernel Randomization**: Randomly selecting a kernel function (including custom R functions) for each base learner.  
- **Feature Subsampling (`mtry`)**: Optionally selecting a random subset of covariates for each base learner (*Random Subspace Method*).

This vignette demonstrates a complete workflow using custom kernels, the bagging functionality, and the `mtry` parameter.

> **Note:** This vignette executes parallel code using the **mirai** package and a Python backend via **reticulate**.  
> Make sure you have Python installed and the `sksurv` module available.

---

## 1. Data Generation

We generate a synthetic dataset with 3 covariates (`x_1`, `x_2`, `x_3`) based on a Weibull survival model with approximately 30% censoring.  
We then split the dataset into training and testing sets.

```{r}
library(FastSurvivalSVM)
library(survival)

# 1. Data Generation
set.seed(123)
df <- data_generation(n = 300, prop_cen = 0.3)

# Split into Training (200) and Testing (100) sets
idx <- sample(1:nrow(df), 200)
train_df <- df[idx, ]
test_df  <- df[-idx, ]

head(train_df)
```

---

## 2. Defining Custom Kernels

One of the strengths of this package is the ability to pass **R functions as kernels**.  
These functions are serialized and sent to the parallel workers automatically.

We define two custom *kernel factories*:

- **Wavelet Kernel**: Useful for capturing complex local non-linearities.  
- **Polynomial Kernel**: A manual implementation of the polynomial kernel.

```{r}
# 2. Custom Kernel Factories

make_wavelet <- function(A = 1) {
  force(A)
  function(x, z) {
    u <- (as.numeric(x) - as.numeric(z)) / A
    prod(cos(1.75 * u) * exp(-0.5 * u^2))
  }
}

make_poly <- function(degree = 3, coef0 = 1) {
  force(degree); force(coef0)
  function(x, z) (sum(as.numeric(x) * as.numeric(z)) + coef0)^degree
}
```

---

## 3. Kernel Specifications

```{r}
kernel_mix <- list(
  linear = list(kernel="linear", alpha=1, rank_ratio=0, fit_intercept=TRUE),
  poly_std = list(kernel="poly", degree=2L, alpha=1, rank_ratio=0, fit_intercept=TRUE),
  wavelet = list(kernel=make_wavelet(A=1), alpha=1, rank_ratio=0, fit_intercept=TRUE),
  poly_fun = list(kernel=make_poly(degree=2L), alpha=1, rank_ratio=0, fit_intercept=TRUE)
)
```

---

## 4. Bagging Ensemble

```{r}
can_run <- reticulate::py_module_available("sksurv") &&
  requireNamespace("mirai", quietly = TRUE)

if (can_run) {
  bag_results <- fastsvm_bagging(
    data       = train_df,
    newdata    = test_df,
    time_col   = "tempo",
    delta_col  = "cens",
    kernels    = kernel_mix,
    B          = 50,
    mtry       = NULL,
    cores      = parallel::detectCores(),
    seed       = 99,
    .progress  = FALSE
  )

  print(bag_results)
}
```

---

## 5. Predictions & Evaluation

```{r}
if (can_run) {
  cat("Preview of Predictions:\n")
  print(head(bag_results$preds))
}
```

```{r}
if (can_run) {
  cidx <- score_fastsvm_bag(bag_results, test_df)
  cat(sprintf("Test C-index: %.4f\n", cidx))
}
```

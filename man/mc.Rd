% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mc.R
\name{mc}
\alias{mc}
\title{Monte Carlo Simulation: Bagging vs Individual Kernels}
\usage{
mc(
  n = 300,
  prop_cen = 0.3,
  kernels,
  B = 50,
  mtry = NULL,
  seed = NULL,
  cores = parallel::detectCores(),
  train_prop = 0.7,
  n_rep = 50L,
  .progress = TRUE
)
}
\arguments{
\item{n}{Integer. Sample size per replication.}

\item{prop_cen}{Numeric. Proportion of censoring (0 to 1). Default is 0.3.}

\item{kernels}{A named list of kernel specifications. The same list is used
for individual fits and for the Bagging ensemble.}

\item{B}{Integer. Number of bootstrap samples for the Bagging model.}

\item{mtry}{Integer or \code{NULL}. Number of variables to randomly sample
at each split in the Bagging model (Random Subspace).}

\item{seed}{Integer or \code{NULL}. Global seed for reproducibility.
This seed is set once at the beginning of the simulation.}

\item{cores}{Integer. Number of cores used by the Bagging model.
This value is passed to \code{\link{fastsvm_bagging}}.}

\item{train_prop}{Numeric. Proportion of data used for training (default 0.7).
The remaining data is used for testing.}

\item{n_rep}{Integer. Number of Monte Carlo replications.}

\item{.progress}{Logical. If \code{TRUE}, show a progress bar during
Monte Carlo replications (delegated to \code{purrr::map()}).}
}
\value{
A \code{data.frame} summarizing the C-index distribution for each
  model across replications, with columns:
  \itemize{
    \item \code{Model}: kernel name or "Bagging".
    \item \code{Mean_C_Index}: mean C-index over replications.
    \item \code{SD_C_Index}: standard deviation of the C-index.
    \item \code{Min_C_Index}: minimum C-index.
    \item \code{Max_C_Index}: maximum C-index.
  }
  The object also carries an attribute \code{"cindex_matrix"} which is a
  matrix of dimension \code{n_rep x n_models} containing the raw C-index
  values for each replication (rows) and model (columns).
}
\description{
This function runs a Monte Carlo simulation comparing individual
\code{FastKernelSurvivalSVM} models (one per kernel specification)
against a Bagging ensemble fitted via \code{\link{fastsvm_bagging}}.
}
\details{
For each replication, the function:
\enumerate{
  \item Generates a dataset via \code{data_generation()}.
  \item Splits it into training and test sets.
  \item Fits one \code{\link{fastsvm}} model for each kernel in \code{kernels}
        and computes the test C-index via \code{\link{score}}.
  \item Fits a Bagging ensemble with \code{\link{fastsvm_bagging}} and
        computes its test C-index via \code{\link{score}}.
}

Bagging is always fitted in parallel according to the \code{cores} argument,
using the internal parallelization provided by \code{\link{fastsvm_bagging}}.
The Monte Carlo loop itself runs serially, but a global progress bar
can be shown via \code{.progress = TRUE}.

The console output is slightly "embellished" with emojis (via the
\pkg{emo} package, if available) to make the simulation more informative
and visually pleasant.
}
\examples{
\dontrun{
if (reticulate::py_module_available("sksurv") &&
    requireNamespace("mirai", quietly = TRUE) &&
    requireNamespace("purrr", quietly = TRUE)) {
  library(FastSurvivalSVM)

  # 1. Custom Kernel Factories
  make_wavelet <- function(A = 1) {
    force(A)
    function(x, z) {
      u <- (as.numeric(x) - as.numeric(z)) / A
      prod(cos(1.75 * u) * exp(-0.5 * u^2))
    }
  }

  make_poly <- function(degree = 3, coef0 = 1) {
    force(degree); force(coef0)
    function(x, z) (sum(as.numeric(x) * as.numeric(z)) + coef0)^degree
  }

  # 2. Kernel Specifications (rank_ratio = 0 for Regression / Time)
  kernel_mix <- list(
    linear   = list(kernel = "linear",
                    alpha  = 1,
                    rank_ratio = 0,
                    fit_intercept = TRUE),
    rbf      = list(kernel = "rbf",
                    alpha  = 0.5,
                    gamma  = 0.1,
                    rank_ratio = 0,
                    fit_intercept = TRUE),
    poly_std = list(kernel = "poly",
                    degree = 2L,
                    alpha  = 1,
                    rank_ratio = 0,
                    fit_intercept = TRUE),
    wavelet  = list(kernel = make_wavelet(A = 1),
                    alpha  = 1,
                    rank_ratio = 0,
                    fit_intercept = TRUE),
    poly_fun = list(kernel = make_poly(degree = 2L),
                    alpha  = 1,
                    rank_ratio = 0,
                    fit_intercept = TRUE)
  )

  # 3. Run Monte Carlo Simulation (e.g. 20 replications)
  results <- mc(
    n           = 300,
    prop_cen    = 0.3,
    kernels     = kernel_mix,
    B           = 50,
    mtry        = NULL,
    seed        = 5,
    cores       = parallel::detectCores(),
    train_prop  = 0.7,
    n_rep       = 20,
    .progress   = TRUE
  )

  print(results)
}
}

}
